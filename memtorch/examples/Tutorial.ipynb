{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <ins>MemTorch Tutorial</ins>\n",
        "## Introduction\n",
        "In this tutorial, you will learn how to use MemTorch to convert Deep Neural Networks (DNNs) to Memristive Deep Neural Networks (MDNNs), and how to simulate non-ideal device characteristics and key peripheral circuitry. MemTorch is a Simulation Framework for Memristive Deep Learning Systems, which integrates directly with the well-known PyTorch Machine Learning (ML) library. MemTorch is formally described in *MemTorch: An Open-source Simulation Framework for Memristive Deep Learning Systems*, which is openly accessible [here](https://arxiv.org/abs/2004.10971).\n",
        "\n",
        "![Overview](https://raw.githubusercontent.com/coreylammie/MemTorch/master/overview.svg)\n"
      ],
      "metadata": {
        "id": "340LIHCnH0dR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation\n",
        "MemTorch can be installed from source using `python setup.py install`:\n",
        "\n",
        "```\n",
        "git clone --recursive https://github.com/coreylammie/MemTorch\n",
        "cd MemTorch\n",
        "python setup.py install\n",
        "```\n",
        "\n",
        "or using `pip install .`, as follows:\n",
        "\n",
        "```\n",
        "git clone --recursive https://github.com/coreylammie/MemTorch\n",
        "cd MemTorch\n",
        "pip install .\n",
        "```\n",
        "\n",
        "*If CUDA is `True` in `setup.py`, CUDA Toolkit 10.1 and Microsoft Visual C++ Build Tools are required. If `CUDA` is False in `setup.py`, Microsoft Visual C++ Build Tools are required.*\n",
        "\n",
        "Alternatively, MemTorch can be installed using the *pip* package-management system:\n",
        "\n",
        "```\n",
        "pip install memtorch-cpu # Supports normal operation\n",
        "pip install memtorch # Supports CUDA and normal operation\n",
        "```\n",
        "\n",
        "A complete API is avaliable [here](https://memtorch.readthedocs.io/).\n",
        "\n",
        "MemTorch can be installed using Jupyter notebooks as follows:"
      ],
      "metadata": {
        "id": "yWhuJyazH0dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps memtorch-cpu\n",
        "!pip install scikit-learn torch torchvision numpy pandas scipy matplotlib seaborn ipython lmfit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmc_0DiwkJG7",
        "outputId": "c3c15f3e-8305-4371-a643-cd465b3f40a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memtorch-cpu\n",
            "  Using cached memtorch-cpu-1.1.6.tar.gz (2.8 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: memtorch-cpu\n",
            "  Building wheel for memtorch-cpu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memtorch-cpu: filename=memtorch_cpu-1.1.6-cp311-cp311-linux_x86_64.whl size=17848576 sha256=3dd07214905ece184e59ed6e772cc26c37c29e528d6236164e85f7ec59361cbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/2c/89/5ae9578759884a637bfef8a809b056ea4dd72c1a66c4434da4\n",
            "Successfully built memtorch-cpu\n",
            "Installing collected packages: memtorch-cpu\n",
            "Successfully installed memtorch-cpu-1.1.6\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (7.34.0)\n",
            "Collecting lmfit\n",
            "  Downloading lmfit-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython) (4.9.0)\n",
            "Collecting asteval>=1.0 (from lmfit)\n",
            "  Downloading asteval-1.0.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting uncertainties>=3.2.2 (from lmfit)\n",
            "  Downloading uncertainties-3.2.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting dill>=0.3.4 (from lmfit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmfit-1.3.3-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteval-1.0.6-py3-none-any.whl (22 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uncertainties-3.2.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uncertainties, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, dill, asteval, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lmfit, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "memtorch-cpu 1.1.6 requires sklearn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asteval-1.0.6 dill-0.3.9 jedi-0.19.2 lmfit-1.3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 uncertainties-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Installation of MemTorch (with CUDA functionality) from source using pip\n",
        "!git clone --recursive https://github.com/coreylammie/MemTorch\n",
        "%cd MemTorch\n",
        "!sed -i 's/CUDA = False/CUDA = True/g' setup.py\n",
        "!pip install ."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MemTorch' already exists and is not an empty directory.\n",
            "/content/MemTorch\n",
            "Processing /content/MemTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (1.6.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (7.34.0)\n",
            "Requirement already satisfied: lmfit in /usr/local/lib/python3.11/dist-packages (from memtorch==1.1.6) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->memtorch==1.1.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->memtorch==1.1.6) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->memtorch==1.1.6) (4.9.0)\n",
            "Requirement already satisfied: asteval>=1.0 in /usr/local/lib/python3.11/dist-packages (from lmfit->memtorch==1.1.6) (1.0.6)\n",
            "Requirement already satisfied: uncertainties>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from lmfit->memtorch==1.1.6) (3.2.2)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from lmfit->memtorch==1.1.6) (0.3.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->memtorch==1.1.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->memtorch==1.1.6) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->memtorch==1.1.6) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->memtorch==1.1.6) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->memtorch==1.1.6) (3.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->memtorch==1.1.6) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->memtorch==1.1.6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->memtorch==1.1.6) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->memtorch==1.1.6) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->memtorch==1.1.6) (3.0.2)\n",
            "Building wheels for collected packages: memtorch\n",
            "  Building wheel for memtorch (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/wheel_builder.py\", line 240, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen codecs>\", line 319, in decode\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "^C\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZM8XW53KH0dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861a78e6-34fa-4f5b-a6af-99b5fb2ac857"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Installation of MemTorch (without CUDA functionality) from source using pip\n",
        "!git clone --recursive https://github.com/coreylammie/MemTorch\n",
        "%cd MemTorch\n",
        "!pip install ."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MemTorch'...\n",
            "remote: Enumerating objects: 1061, done.\u001b[K\n",
            "remote: Counting objects: 100% (462/462), done.\u001b[K\n",
            "remote: Compressing objects: 100% (261/261), done.\u001b[K\n",
            "remote: Total 1061 (delta 333), reused 201 (delta 201), pack-reused 599 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1061/1061), 12.06 MiB | 16.44 MiB/s, done.\n",
            "Resolving deltas: 100% (625/625), done.\n",
            "Submodule 'memtorch/submodules/eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'memtorch/submodules/eigen'\n",
            "Cloning into '/content/MemTorch/memtorch/submodules/eigen'...\n",
            "remote: Enumerating objects: 127725, done.        \n",
            "remote: Counting objects: 100% (1062/1062), done.        \n",
            "remote: Compressing objects: 100% (459/459), done.        \n",
            "remote: Total 127725 (delta 641), reused 1016 (delta 600), pack-reused 126663 (from 1)        \n",
            "Receiving objects: 100% (127725/127725), 106.70 MiB | 21.45 MiB/s, done.\n",
            "Resolving deltas: 100% (105728/105728), done.\n",
            "Submodule path 'memtorch/submodules/eigen': checked out '1f4c0311cda3403999b702c996898af5707973a9'\n",
            "/content/MemTorch\n",
            "Processing /content/MemTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu==1.1.6) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu==1.1.6) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu==1.1.6) (1.14.1)\n",
            "Collecting sklearn (from memtorch-cpu==1.1.6)\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "metadata": {
        "id": "VoBS6Y0FH0dX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8faa32-5224-4baa-eb4a-7986212f186f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Installation of MemTorch (with CUDA functionality) using pip\n",
        "!pip install memtorch"
      ],
      "outputs": [],
      "metadata": {
        "id": "83ToE85BH0dY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Installation of MemTorch (without CUDA functionality) using pip\n",
        "!pip install memtorch-cpu"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memtorch-cpu\n",
            "  Using cached memtorch-cpu-1.1.6.tar.gz (2.8 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from memtorch-cpu) (1.14.1)\n",
            "Collecting sklearn (from memtorch-cpu)\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "metadata": {
        "id": "g49HrYnhH0dY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee40807-a0de-4e79-db1f-f3d07027c450"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training and Benchmarking a Deep Neural Network Using MNIST"
      ],
      "metadata": {
        "id": "qBYEsnSav5E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MemTorch can currently be used to simulate the inference routines of MDNNs. Consequently, prior to conversion, DNNs must be either defined and trained using PyTorch or imported using PyTorch.\n",
        "\n",
        "In this tutorial, a simple DNN architecture is trained and benchmarked using the MNIST hand-written character classification data set.\n",
        "\n",
        "* The MNIST data set consists of 70,000 28x28 greyscale images in 10 balanced classes, representing the numbers 0-9. There are 60,000 training images and 10,000 test images.\n",
        "* In the cell below, a DNN is trained for 10 epochs with a batch size of $\\Im=256$.\n",
        "* An initial learning rate of $\\eta = 1e-1$ is used, which is decayed by an order of magnitude after 5 training epochs.\n",
        "* Adam is used to optimize network parameters and Cross Entropy (CE) is used to determine network losses.\n",
        "* `memtorch.utils.LoadMNIST` is used to load the MNIST training and test sets. After each epoch, the model is evaluated using the MNIST test set.\n",
        "* The model that achieves the highest test set accuracy is saved as *trained_model.pt*."
      ],
      "metadata": {
        "id": "HCy9QqPHv5E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import memtorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from memtorch.utils import LoadMNIST\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def test(model, test_loader):\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        output = model(data.to(device))\n",
        "        pred = output.data.max(1)[1]\n",
        "        correct += pred.eq(target.to(device).data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    return 100. * float(correct) / float(len(test_loader.dataset))\n",
        "\n",
        "device = torch.device('cpu' if 'cpu' in memtorch.__version__ else 'cuda')\n",
        "epochs = 10\n",
        "learning_rate = 1e-1\n",
        "step_lr = 5\n",
        "batch_size = 256\n",
        "train_loader, validation_loader, test_loader = LoadMNIST(batch_size=batch_size, validation=False)\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "best_accuracy = 0\n",
        "for epoch in range(0, epochs):\n",
        "    print('Epoch: [%d]\\t\\t' % (epoch + 1), end='')\n",
        "    if epoch % step_lr == 0:\n",
        "        learning_rate = learning_rate * 0.1\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = learning_rate\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = test(model, test_loader)\n",
        "    print('%2.2f%%' % accuracy)\n",
        "    if accuracy > best_accuracy:\n",
        "        torch.save(model.state_dict(), 'trained_model.pt')\n",
        "        best_accuracy = accuracy"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MemTorch/memtorch/bh/nonideality/DeviceFaults.py:116: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  ) and arg.name is not \"validate_args\":\n",
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.47MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 161kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.04MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1]\t\t98.77%\n",
            "Epoch: [2]\t\t98.76%\n",
            "Epoch: [3]\t\t99.01%\n",
            "Epoch: [4]\t\t98.95%\n",
            "Epoch: [5]\t\t98.85%\n",
            "Epoch: [6]\t\t99.28%\n",
            "Epoch: [7]\t\t99.33%\n",
            "Epoch: [8]\t\t99.29%\n",
            "Epoch: [9]\t\t99.30%\n",
            "Epoch: [10]\t\t99.30%\n"
          ]
        }
      ],
      "metadata": {
        "id": "jVH_tu3tv5E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c687c2e-6a70-4f14-967b-767de45d5e09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conversion of a Deep Neural Network to a Memristive Deep Neural Network"
      ],
      "metadata": {
        "id": "Ag8Z6Rn_v5E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within MemTorch, `memtorch.mn.Module.patch_model` can be used to convert DNNs to a MDNNs. Prior to conversion, a memristive device model must be defined and characterized in part (prior to the introduction of other non-ideal device characteristics).\n",
        "\n",
        "In the cell below:\n",
        "* A reference (base) memristor model from `memtorch.bh.memristor` is defined.\n",
        "* Optional reference memristor keyword arguments are set.\n",
        "* A `memtorch.bh.memristor.Memristor` object is instantiated\n",
        "* The hysteresis loop of the instantiated memristor object is generated/plotted.\n",
        "* The bipolar switching behaviour of the instantiated memristor object is generated/plotted."
      ],
      "metadata": {
        "id": "lyt9qHvAv5E9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "reference_memristor_params = {'time_series_resolution': 1e-10}\n",
        "memristor = reference_memristor(**reference_memristor_params)\n",
        "memristor.plot_hysteresis_loop()\n",
        "memristor.plot_bipolar_switching_behaviour()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'memtorch.bh' has no attribute 'memristor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-88b5469def5a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreference_memristor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemristor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVTEAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreference_memristor_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'time_series_resolution'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmemristor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_memristor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mreference_memristor_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmemristor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_hysteresis_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmemristor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_bipolar_switching_behaviour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'memtorch.bh' has no attribute 'memristor'"
          ]
        }
      ],
      "metadata": {
        "id": "dRMGKP-lv5E-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "b8e3a104-19f3-463f-d05b-8a87f14c1efa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, the trained DNN from Section 2 is converted to an equivalent MDNN, where all convolutional layers are replaced with memristive-equivalent layers. While only *Conv2d* layers are converted for demonstration purposes, we note that MemTorch currently supports conversion of *Conv1d*, *Conv2d*, *Conv3d*, and *Linear* layers. Specifically:\n",
        "* `memtorch.bh.map.Parameter.naive_map` is used to convert the weights within all `torch.nn.Conv2d` layers to equivalent conductance values, to be programmed to the two memristive devices used to represent each weight (positive and negative, respectively).\n",
        "* `tile_shape` is set to (128, 128), so that modular crossbar tiles of size 128x128 are used to represent weights.\n",
        "* `ADC_resolution` is set to 8 to set the bit width of all emulated Analogue to Digital Converters (ADC).\n",
        "* `ADC_overflow` is used to set the initial overflow rate of each ADC.\n",
        "* `quant_method` is used to set the quantization method used (linear, by default).\n",
        "* `transistor` is set to `True`, so a 1T1R arrangement is simulated.\n",
        "* `programming_routine` is set to `None` to skip device-level simulation of the programming routine.\n",
        "\n",
        "\n",
        "\n",
        "We note if `transistor` is `False` `programming_routine` must not be `None`. In which case, device-level simulation is performed for each device using `memtorch.bh.crossbar.gen_programming_signal` and `memtorch.bh.memristor.Memristor.simulate`, which use finite differences to model internal device dynamics. As `scheme` is not defined, a double-column parameter representation scheme is adopted. Finally, `max_input_voltage` is 0.3, meaning inputs to each layer are encoded between -0.3V and +0.3V."
      ],
      "metadata": {
        "id": "b0kLErl0v5FC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import copy\n",
        "from memtorch.mn.Module import patch_model\n",
        "from memtorch.map.Input import naive_scale\n",
        "from memtorch.map.Parameter import naive_map\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
        "patched_model = patch_model(copy.deepcopy(model),\n",
        "                          memristor_model=reference_memristor,\n",
        "                          memristor_model_params=reference_memristor_params,\n",
        "                          module_parameters_to_patch=[torch.nn.Conv2d],\n",
        "                          mapping_routine=naive_map,\n",
        "                          transistor=True,\n",
        "                          programming_routine=None,\n",
        "                          tile_shape=(128, 128),\n",
        "                          max_input_voltage=0.3,\n",
        "                          scaling_routine=naive_scale,\n",
        "                          ADC_resolution=8,\n",
        "                          ADC_overflow_rate=0.,\n",
        "                          quant_method='linear')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'reference_memristor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bed06d6defe0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m patched_model = patch_model(copy.deepcopy(model),\n\u001b[0;32m---> 10\u001b[0;31m                           \u001b[0mmemristor_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_memristor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                           \u001b[0mmemristor_model_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_memristor_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                           \u001b[0mmodule_parameters_to_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reference_memristor' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "oJWSTW5Qv5FD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "7dc9baae-7f57-47ad-a9c8-c568061dab7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, all patched `torch.nn.Conv2d` layers are tuned using linear regression. A randomly generated tensor of size (8, `self.in_channels`, 32, 32) is propagated through each memristive layer and each legacy layer (accessible using `layer.forward_legacy`). `sklearn.linear_model.LinearRegression` is used to determine the coefficient and intercept between the linear relationship of each set of outputs, which is used to define the `transform_output` lamdba function, that maps the output of each layer to their equivalent representations."
      ],
      "metadata": {
        "id": "5WeMLQXBH0de"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "patched_model.tune_()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Mam3ggffv5FG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, in the cell below, the converted and tuned MDNN is benchmarked using the MNIST test data set.\n",
        "*Note: This cell may take a considerable amount of time to run.*"
      ],
      "metadata": {
        "id": "YN_U95V_H0de"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "U5F0muXPv5FK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Modeling Non-Ideal Device Characteristics"
      ],
      "metadata": {
        "id": "eV8IJSH6v5FN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Non-ideal device characteristics can either be encapsulated within device specific memristive models, or introduced to base (generic) models after conversion, using `memtorch.bh.nonideality.NonIdeality.apply_nonidealities`. Currently, the following non-ideal device characteristics are supported:\n",
        "* `memtorch.bh.nonideality.DeviceFaults`\n",
        "* `memtorch.bh.nonideality.Endurance` and `memtorch.bh.nonideality.Retention`\n",
        "* `memtorch.bh.nonideality.FiniteConductanceStates`\n",
        "* `memtorch.bh.nonideality.NonLinear`\n",
        "\n",
        "Stochastic parameters, used to model process variances, can be defined using `memtorch.bh.StochaticParameter`. The introduction of each type of non ideal device characteristic is demonstrated below.\n"
      ],
      "metadata": {
        "id": "R4H9f4d248V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Modeling Device Faults\n",
        "\n",
        "Memristive devices are susceptible to failure, by either failing to eletroform at a pristine state, or becoming stuck at high or low resistance states. MemTorch incorporates a specific function for accounting for device failure, `memtorch.bh.nonideality.DeviceFaults`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `lrs_proportion` is set to 0.25, so that 25% of devices are assumed to fail to a low resistance state.\n",
        "* `hrs_proportion` is set to 0.10, so that 15% of devices are assumed to fail to a high resistance state.\n",
        "\n",
        "It is assumed that the total proportion of devices set to a high resistance state is equal to the proportion of devices that fail to eletroform at pristine states plus the proportion of devices stuck at a high resistance state.\n",
        "\n"
      ],
      "metadata": {
        "id": "pewV5scsH2ZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.DeviceFaults],\n",
        "                                  lrs_proportion=0.25,\n",
        "                                  hrs_proportion=0.10,\n",
        "                                  electroform_proportion=0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WEJmY_ENH0dg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3cb7a12fd805>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatched_model_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "KTxU1vckH0dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "92686ee7-138b-4bf0-858c-2061effc299c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Modeling Device Endurance and Retention\n",
        "\n",
        "Memristive devices possess non-ideal endurance and retention properties, which should be accounted for. MemTorch incorporates specific functions for accounting for device endurance and retention characteristics, `memtorch.bh.nonideality.Endurance`, and `memtorch.bh.nonideality.Retention`, respectively.\n",
        "\n",
        "All endurance and retention models are defined in `memtorch.bh.nonideality.endurance_retention_models`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `x`, the number of SET-RESET cycles is set to be equal to 10,000.\n",
        "* Endurance characteristics are accounted for using `memtorch.bh.nonideality.NonIdeality.Endurance` and `memtorch.bh.nonideality.endurance_retention_models.model_endurance_retention`.\n",
        "* `operation_mode` within `endurance_model_kwargs` is set to `sudden`, so that sudden failure is modeled, and various other model arguments are set.\n"
      ],
      "metadata": {
        "id": "D2Vcpuuw5D_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.Endurance],\n",
        "                                  x=1e4,\n",
        "                                  endurance_model=memtorch.bh.nonideality.endurance_retention_models.model_endurance_retention,\n",
        "                                  endurance_model_kwargs={\n",
        "                                        \"operation_mode\": memtorch.bh.nonideality.endurance_retention_models.OperationMode.sudden,\n",
        "                                        \"p_lrs\": [1, 0, 0, 0],\n",
        "                                        \"stable_resistance_lrs\": 100,\n",
        "                                        \"p_hrs\": [1, 0, 0, 0],\n",
        "                                        \"stable_resistance_hrs\": 1000,\n",
        "                                        \"cell_size\": 10,\n",
        "                                        \"temperature\": 350,\n",
        "                                  })"
      ],
      "outputs": [],
      "metadata": {
        "id": "4thsaVDEv5FS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "fl7_hStXH0dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `time`, the retention time, is set to be equal to 1,000s.\n",
        "* Retention characteristics are accounted for using `memtorch.bh.nonideality.NonIdeality.Retention` and `memtorch.bh.nonideality.endurance_retention_models.model_conductance_drift`.\n",
        "* `initial_time` within `retention_model_kwargs`, the initial time, is set to be equal to 1s.\n",
        "* `drift_coefficient` within `retention_model_kwargs` is set to be equal to 0.1."
      ],
      "metadata": {
        "id": "KykmIom1H0dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.Retention],\n",
        "                                  time=1e3,\n",
        "                                  retention_model=memtorch.bh.nonideality.endurance_retention_models.model_conductance_drift,\n",
        "                                  retention_model_kwargs={\n",
        "                                        \"initial_time\": 1,\n",
        "                                        \"drift_coefficient\": 0.1,\n",
        "                                  })"
      ],
      "outputs": [],
      "metadata": {
        "id": "jTNNAcCiH0dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "gV1ANo6-H0di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Modeling a Finite Number of Conductance States\n",
        "\n",
        "Realistic memristive devices are non-ideal and have a finite number of stable discrete electrically switchable conductance states, bounded by a low conductance semiconducting state, and a high-conductance metallic state. MemTorch incorporates a specific function for accounting for devices with a finite number of conductance states, `memtorch.bh.nonideality.FiniteConductanceStates`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* A finite number of conductance states are accounted for using `memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates`.\n",
        "* `conductance_states` is set to be equal to 5, to model 5 evenly-distributed conductance states."
      ],
      "metadata": {
        "id": "rR03gyJVH0di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
        "                                  conductance_states=5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "UH0e7AtWH0di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "zA6Bc-PPH0di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Modeling Non-Linear Device Characteristics\n",
        "\n",
        "Non-ideal memristive devices have non-linear I/V device characteristics, especially at high voltages, which are difficult to accurately and efficiently model. The `memtorch.bh.nonideality.NonLinear.apply_non_linear` function can be used to efficiently model non-linear device I/V characteristics during inference for devices with an infinite number of discrete conductance states, and for devices with a finite number of conductance states.\n",
        "\n",
        "For cases where devices are not simulated using their internal dynamics, it is assumed that the change in conductance during read cycles is negligible.\n",
        "\n",
        "Within MemTorch, `memtorch.bh.nonideality.NonLinear.apply_non_linear` uses two methods to effectively model non-linear device I/V characteristics:\n",
        "\n",
        "1. During inference, each device is simulated for timesteps of duration `device.time_series_resolution` using `device.simulate`.\n",
        "2. Post weight mapping and programming, the I/V characteristics of each device are determined using a single reset voltage sweep.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* Non-linear device characteristics are accounted for using `memtorch.bh.nonideality.NonLinear`.\n",
        "* `simulate` is set to be equal to `True`, so during inference each device is simulated.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7FBLj9-mH0di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.NonLinear],\n",
        "                                  simulate=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F-0leLIdH0di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "-AWwwouiH0dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* Non-linear device characteristics are accounted for using `memtorch.bh.nonideality.NonLinear`.\n",
        "* `simulate` is not set, so the I/V characteristics of each device are determined using a single reset voltage sweep.\n",
        "* `sweep_duration` is set to be equal to 2s.\n",
        "* `sweep_voltage_signal_amplitude` is set to be equal to 1V.\n",
        "* `sweep_voltage_signal_frequency` is set to be equal to 0.5Hz.\n"
      ],
      "metadata": {
        "id": "F2W039iPH0dj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.NonLinear],\n",
        "                                  sweep_duration=2,\n",
        "                                  sweep_voltage_signal_amplitude=1,\n",
        "                                  sweep_voltage_signal_frequency=0.5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SZOh4WJZH0dj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(test(patched_model_, test_loader))"
      ],
      "outputs": [],
      "metadata": {
        "id": "SnPpuvPaH0dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Modeling Stochastic Parameters"
      ],
      "metadata": {
        "id": "zTA0KyOEH0dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MemTorch supports the usage of stochastic parameters for higher flexibility to simply account for process variances using `memtorch.bh.StochasticParameter.StochasticParameter`. Stochastic parameters can be used when defining device characteristics.\n",
        "\n",
        "In the cell below:\n",
        "* A memristor object is characterised using stochastic parameters defining low and high resistance states.\n",
        "* The memristor object is instantiated, and the hysteresis loop and bipolar switching behaviour of the instantiated memristor object is generated/plotted.\n",
        "\n",
        "Each time the memristor object is instantiated, stochastic parameters will be resampled.\n"
      ],
      "metadata": {
        "id": "HoS7ZHhdH0dk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import memtorch\n",
        "\n",
        "reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "reference_memristor_params = {'time_series_resolution': 1e-10,\n",
        "                              'r_off': memtorch.bh.StochasticParameter(loc=1000, scale=200, min=2),\n",
        "                              'r_on': memtorch.bh.StochasticParameter(loc=5000, scale=sigma, min=1)}\n",
        "\n",
        "memristor = reference_memristor(**reference_memristor_params)\n",
        "memristor.plot_hysteresis_loop()\n",
        "memristor.plot_bipolar_switching_behaviour()"
      ],
      "outputs": [],
      "metadata": {
        "id": "i2Kozl3dH0dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Remarks\n",
        "A complete API is avaliable [here](https://memtorch.readthedocs.io/). To learn how to use MemTorch, and to reproduce results of ‘_MemTorch: An Open-source Simulation Framework for Memristive Deep Learning Systems_’, we provide numerous tutorials in the form of Jupyter notebooks [here](https://memtorch.readthedocs.io/en/latest/tutorials.html).\n",
        "\n",
        "Current issues, feature requests and improvements are welcome, and are tracked using: https://github.com/coreylammie/MemTorch/projects/1. These should be reported [here](https://github.com/coreylammie/MemTorch/issues)."
      ],
      "metadata": {
        "id": "MSOaAOQAH0dk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}